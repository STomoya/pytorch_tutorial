{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms, data, dataloaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(\"./data\",\n",
    "                                            download=True,\n",
    "                                            train=True,\n",
    "                                            transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(\"./data\",\n",
    "                                            download=True,\n",
    "                                            train=False,\n",
    "                                            transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# plotter\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 +0.5\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/fashion_mnist_experiment_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "writer.add_image(\"four_fashion_mnist_images\", img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/imlk/デスクトップ/ADMIN/pytorch/.venv/lib/python3.7/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/home/imlk/デスクトップ/ADMIN/pytorch/.venv/lib/python3.7/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.0.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
